{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#2656a3;\">**Msc. BDS Module - Data Engineering and Machine Learning Operations in Business (MLOPs)** </span> <span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Pipeline</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Feature selection.\n",
    "2. Creating a Feature View.\n",
    "3. Training datasets creation - splitting into train and test sets.\n",
    "4. Training the model.\n",
    "5. Register the model to Hopsworks Model Registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/simran-padam/LSTM-Multivariate-Time-Series/blob/main/LSTM_Multivariate_Time_Series.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> ‚öôÔ∏è Import of libraries and packages\n",
    "We start with importing some of the necessary libraries needed for this notebook and warnings to avoid unnecessary distractions and keep output clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üì° Connecting to Hopsworks Feature Store\n",
    "We connect to Hopsworks Feature Store so we can retrieve the Feature Groups and select features for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/556180\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "# Importing the hopsworks module for interacting with the Hopsworks platform\n",
    "import hopsworks\n",
    "\n",
    "# Logging into the Hopsworks project\n",
    "project = hopsworks.login()\n",
    "\n",
    "# Getting the feature store from the project\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the feature groups\n",
    "electricity_fg = fs.get_feature_group(\n",
    "    name='electricity_prices',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather_measurements',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "danish_calendar_fg = fs.get_feature_group(\n",
    "    name='dk_calendar',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üñç Feature View Creation and Retrieving </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first select the features that we want to include for model training.\n",
    "\n",
    "Since we specified `primary_key`as `date` and `timestamp` in `1_feature_backfill` we can now join them together for the `electricity_fg`, `weather_fg` and `danish_holiday_fg`.\n",
    "\n",
    "`join_type` specifies the type of join to perform. An inner join refers to only retaining the rows based on the keys present in all joined DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data and join them together and except duplicate columns\n",
    "selected_features_training = electricity_fg.select_all()\\\n",
    "    .join(weather_fg.select_except([\"timestamp\", \"datetime\", \"hour\"]), join_type=\"inner\")\\\n",
    "    .join(danish_calendar_fg.select_all(), join_type=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation_functions = {\n",
    "#         \"hour\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"dk1_spotpricedkk_kwh\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"temperature_2m\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"relative_humidity_2m\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"precipitation\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"rain\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"snowfall\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"weather_code\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"cloud_cover\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"wind_speed_10m\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"wind_gusts_10m\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"dayofweek\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"day\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"month\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"year\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#         \"workday\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.40s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>dk1_spotpricedkk_kwh</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>workday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1682280000000</td>\n",
       "      <td>2023-04-23 20:00:00+00:00</td>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>20</td>\n",
       "      <td>1.02178</td>\n",
       "      <td>10.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1678816800000</td>\n",
       "      <td>2023-03-14 18:00:00+00:00</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>18</td>\n",
       "      <td>0.77461</td>\n",
       "      <td>0.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1697259600000</td>\n",
       "      <td>2023-10-14 05:00:00+00:00</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.01551</td>\n",
       "      <td>9.8</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>54.7</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1657170000000</td>\n",
       "      <td>2022-07-07 05:00:00+00:00</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>5</td>\n",
       "      <td>1.15795</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>31.3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1647597600000</td>\n",
       "      <td>2022-03-18 10:00:00+00:00</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>10</td>\n",
       "      <td>1.48754</td>\n",
       "      <td>8.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>45.4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp                  datetime        date  hour  \\\n",
       "0  1682280000000 2023-04-23 20:00:00+00:00  2023-04-23    20   \n",
       "1  1678816800000 2023-03-14 18:00:00+00:00  2023-03-14    18   \n",
       "2  1697259600000 2023-10-14 05:00:00+00:00  2023-10-14     5   \n",
       "3  1657170000000 2022-07-07 05:00:00+00:00  2022-07-07     5   \n",
       "4  1647597600000 2022-03-18 10:00:00+00:00  2022-03-18    10   \n",
       "\n",
       "   dk1_spotpricedkk_kwh  temperature_2m  relative_humidity_2m  precipitation  \\\n",
       "0               1.02178            10.4                  74.0            0.0   \n",
       "1               0.77461             0.5                  88.0            0.0   \n",
       "2              -0.01551             9.8                  71.0            0.0   \n",
       "3               1.15795            15.0                  90.0            0.1   \n",
       "4               1.48754             8.4                  60.0            0.0   \n",
       "\n",
       "   rain  snowfall  weather_code  cloud_cover  wind_speed_10m  wind_gusts_10m  \\\n",
       "0   0.0       0.0           3.0        100.0             7.6            10.1   \n",
       "1   0.0       0.0           0.0          0.0            11.6            22.7   \n",
       "2   0.0       0.0           1.0         23.0            29.5            54.7   \n",
       "3   0.1       0.0          51.0         59.0            16.6            31.3   \n",
       "4   0.0       0.0           0.0          0.0            21.9            45.4   \n",
       "\n",
       "   dayofweek  day  month  year  workday  \n",
       "0          6   23      4  2023        0  \n",
       "1          1   14      3  2023        1  \n",
       "2          5   14     10  2023        0  \n",
       "3          3    7      7  2022        1  \n",
       "4          4   18      3  2022        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the selected features\n",
    "selected_features_training.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Feature View` stands between the **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create a **Feature View** which stores a metadata of our data. Having the **Feature View** we can create a **Training Dataset**.\n",
    "\n",
    "In order to create Feature View we can use `fs.get_or_create_feature_view()` method.\n",
    "\n",
    "We can specify parameters:\n",
    "\n",
    "- `name` - Name of the feature view to create.\n",
    "- `version` - Version of the feature view to create.\n",
    "- `query` - Query object with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting or creating a feature view named 'dk1_electricity_training_feature_view'\n",
    "version = 1\n",
    "feature_view_training = fs.get_or_create_feature_view(\n",
    "    name='dk1_electricity_training_feature_view',\n",
    "    version=version,\n",
    "    query=selected_features_training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting or creating a feature view named 'dk1_electricity_training_feature_view'\n",
    "# version = 1\n",
    "# feature_view_training = fs.get_or_create_feature_view(\n",
    "#     name='lstm_dk1_electricity_training_feature_view',\n",
    "#     version=version,\n",
    "#     transformation_functions=transformation_functions,\n",
    "#     query=selected_features_training,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks, a training dataset is generated from a query defined by the parent FeatureView, which determines the set of features.\n",
    "\n",
    "**Training Dataset may contain splits such as:** \n",
    "* Training set: This subset of the training data is utilized for model training.\n",
    "* Validation set: Used for evaluating hyperparameters during model training. *(We have not included a validation set for this project)*\n",
    "* Test set: Reserved as a holdout subset of training data for evaluating a trained model's performance.\n",
    "\n",
    "Training dataset is created using `fs.training_data()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.12s) \n",
      "2024-05-18 22:09:45,924 WARNING: VersionWarning: Incremented version to `2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve training data from the feature view 'feature_view_training', assigning the features to 'X'.\n",
    "df, _ = feature_view_training.training_data(\n",
    "    description = 'LSTM Electricity Prices Training Dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='timestamp', ascending=True, inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>dk1_spotpricedkk_kwh</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>workday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1640995200000</td>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374101</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.255924</td>\n",
       "      <td>0.293403</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1640998800000</td>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.367453</td>\n",
       "      <td>0.424107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.255924</td>\n",
       "      <td>0.243056</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1641002400000</td>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.368895</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.244866</td>\n",
       "      <td>0.246528</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1641006000000</td>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.370601</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>0.230903</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1641009600000</td>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.364663</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167457</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp                   datetime        date      hour  \\\n",
       "0  1640995200000  2022-01-01 00:00:00+00:00  2022-01-01  0.000000   \n",
       "1  1640998800000  2022-01-01 01:00:00+00:00  2022-01-01  0.043478   \n",
       "2  1641002400000  2022-01-01 02:00:00+00:00  2022-01-01  0.086957   \n",
       "3  1641006000000  2022-01-01 03:00:00+00:00  2022-01-01  0.130435   \n",
       "4  1641009600000  2022-01-01 04:00:00+00:00  2022-01-01  0.173913   \n",
       "\n",
       "   dk1_spotpricedkk_kwh  temperature_2m  relative_humidity_2m  precipitation  \\\n",
       "0              0.374101        0.426339              1.000000            0.0   \n",
       "1              0.367453        0.424107              1.000000            0.0   \n",
       "2              0.368895        0.426339              0.986667            0.0   \n",
       "3              0.370601        0.426339              1.000000            0.0   \n",
       "4              0.364663        0.426339              0.986667            0.0   \n",
       "\n",
       "   rain  snowfall  weather_code  cloud_cover  wind_speed_10m  wind_gusts_10m  \\\n",
       "0   0.0       0.0          0.04          1.0        0.255924        0.293403   \n",
       "1   0.0       0.0          0.04          1.0        0.255924        0.243056   \n",
       "2   0.0       0.0          0.04          1.0        0.244866        0.246528   \n",
       "3   0.0       0.0          0.04          1.0        0.200632        0.230903   \n",
       "4   0.0       0.0          0.04          1.0        0.167457        0.187500   \n",
       "\n",
       "   dayofweek  day  month  year  workday  \n",
       "0   0.833333  0.0    0.0   0.0      0.0  \n",
       "1   0.833333  0.0    0.0   0.0      0.0  \n",
       "2   0.833333  0.0    0.0   0.0      0.0  \n",
       "3   0.833333  0.0    0.0   0.0      0.0  \n",
       "4   0.833333  0.0    0.0   0.0      0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#2656a3;\"> ‚õ≥Ô∏è Dataset with train and test splits</span>\n",
    "\n",
    "Here we define our train and test splits for traning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['timestamp', 'datetime', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing data sets with 80% of the data for training and 20% for testing\n",
    "train_size = int(len(df) * 0.8)\n",
    "\n",
    "X_train, X_test = df[:train_size], df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train.pop('dk1_spotpricedkk_kwh')\n",
    "y_test = X_test.pop('dk1_spotpricedkk_kwh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>workday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16394</th>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157978</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16395</th>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.323661</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.146701</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150079</td>\n",
       "      <td>0.143229</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16397</th>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145340</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.325893</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.133681</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hour  temperature_2m  relative_humidity_2m  precipitation  \\\n",
       "16394  0.173913        0.328125              0.960000       0.017143   \n",
       "16395  0.217391        0.323661              0.973333       0.017143   \n",
       "16396  0.260870        0.321429              0.973333       0.005714   \n",
       "16397  0.304348        0.321429              0.946667       0.000000   \n",
       "16398  0.347826        0.325893              0.933333       0.000000   \n",
       "\n",
       "           rain  snowfall  weather_code  cloud_cover  wind_speed_10m  \\\n",
       "16394  0.017143       0.0          0.68          1.0        0.157978   \n",
       "16395  0.017143       0.0          0.68          1.0        0.156398   \n",
       "16396  0.005714       0.0          0.68          1.0        0.150079   \n",
       "16397  0.000000       0.0          0.04          1.0        0.145340   \n",
       "16398  0.000000       0.0          0.04          1.0        0.140600   \n",
       "\n",
       "       wind_gusts_10m  dayofweek       day     month  year  workday  \n",
       "16394        0.152778   0.333333  0.466667  0.909091   0.5      1.0  \n",
       "16395        0.146701   0.333333  0.466667  0.909091   0.5      1.0  \n",
       "16396        0.143229   0.333333  0.466667  0.909091   0.5      1.0  \n",
       "16397        0.140625   0.333333  0.466667  0.909091   0.5      1.0  \n",
       "16398        0.133681   0.333333  0.466667  0.909091   0.5      1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first 5 rows of the test dataset (X_test)\n",
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xscaler = MinMaxScaler() #not outlier sensitive as comapred to Standard Scaler\n",
    "yscaler = MinMaxScaler()\n",
    "\n",
    "xscaler.fit(X_train.loc[:, keep_list_final])\n",
    "yscaler.fit(y_train)\n",
    "\n",
    "X_scaled_tr = xscaler.transform(X_train.loc[:, keep_list_final])\n",
    "y_scaled_tr = yscaler.transform(y_train)\n",
    "\n",
    "pd.DataFrame(X_scaled_tr).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\">üóÉ Window timeseries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "  #\n",
    "  # n_past ==> no of past observations\n",
    "  #\n",
    "  # n_future ==> no of future observations \n",
    "  #\n",
    "  X, y = list(), list()\n",
    "  for window_start in range(len(series)):\n",
    "    past_end = window_start + n_past\n",
    "    future_end = past_end + n_future\n",
    "    if future_end > len(series):\n",
    "      break\n",
    "    # slicing the past and future parts of the window\n",
    "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "    X.append(past)\n",
    "    y.append(future)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case, let‚Äôs assume that given the past 10 days observation, we need to forecast the next 5 days observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 240 # Observations for 10 days\n",
    "n_future = 120 # Predictions for the next 5 day \n",
    "n_features = 15 # Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(0, 240, None), slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\energy2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(0, 240, None), slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43msplit_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_past\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_future\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_train \u001b[38;5;241m=\u001b[39m split_series(y_train,n_past, n_future)\n",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m, in \u001b[0;36msplit_series\u001b[1;34m(series, n_past, n_future)\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# slicing the past and future parts of the window\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m past, future \u001b[38;5;241m=\u001b[39m \u001b[43mseries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwindow_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mpast_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m, series[past_end:future_end, :]\n\u001b[0;32m     15\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(past)\n\u001b[0;32m     16\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(future)\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\energy2\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\energy2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\energy2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5975\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5972\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5973\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5974\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5975\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(0, 240, None), slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "X_train = split_series(X_train,n_past, n_future)\n",
    "y_train = split_series(y_train,n_past, n_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert both the train and test data into samples using the split_series function.\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "X_test = split_series(X_test.values,n_past, n_future)\n",
    "y_test = split_series(y_test.values,n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\">üß¨ Modeling</span>\n",
    "\n",
    "For Modeling we initialize the `XGBoost Regressor`.\n",
    "\n",
    "The XGBoost Regressor is a powerful and versatile algorithm known for its effectiveness in a wide range of regression tasks, including predictive modeling and time series forecasting. Specifically tailored for regression tasks, it aims to predict continuous numerical values. The algorithm constructs an ensemble of regression trees, optimizing them to minimize a specified loss function, commonly the mean squared error for regression tasks. Ultimately, the final prediction is derived by aggregating the predictions of individual trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above feature importance plot features like `temperature`, `day`, `hour` and `month` are most important for predicting the dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'>üóÑ Model Registry</span>\n",
    "\n",
    "The Model Registry in Hopsworks enable us to store the trained model. The model registry centralizes model management, enabling models to be securely accessed and governed. We can also save model metrics with the model, enabling the user to understand performance of the model on test (or unseen) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n",
    "A model schema defines the structure and format of the input and output data that a machine learning model expects and produces, respectively. It serves as a **blueprint** for understanding how to interact with the model in terms of input features and output predictions. In the context of the Hopsworks platform, a model schema is typically defined using the Schema class, which specifies the features expected in the input data and the target variable in the output data. This schema helps ensure consistency and compatibility between the model and the data it operates on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\">‚è≠Ô∏è **Next:** Part 04: Batch Inference </span>\n",
    "\n",
    "Next notebook we will use the registered model to make predictions based on the batch data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bds-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
